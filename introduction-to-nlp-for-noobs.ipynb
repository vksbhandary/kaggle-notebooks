{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Through this notebook, I am trying to give very basic introduction to natural language processing pipeline. This notebook is related to this [blog](http://) on medium. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to competition\n",
    "\n",
    "Quora is a platform that empowers people to learn from each others. In this platform people can ask question and any member can answer to the questions. But there are some questions that intend to make statement rather than look for answers. These questions are labeled as 'insincere'.\n",
    "\n",
    "In this kernel we use the dataset provided in the above mentioned [competiotion](https://www.kaggle.com/c/quora-insincere-questions-classification), where we are supposed to label each question if it is 'insincere' or not. The dataset contained 1.31 million questions which are labeled 0 or 1 (1 is for 'insincere' and 0 is for 'sincere'). Out of 1.31 million there are about 80k questions that are labeled as 'insincere'.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Planning\n",
    "\n",
    "In order to solve this problem, we need to build a model that can classify a question if its sincere or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['train.csv', 'sample_submission.csv', 'embeddings', 'test.csv']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "\n",
    "print(os.listdir(\"../input\"))\n",
    "import operator \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_uuid": "6fc0108c231dc52717f47a46328ac03d7ec06a8a"
   },
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "a0111115b44a9c03ec8e12715b616ba9e9e9d2f4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import re, string\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras\n",
    "\n",
    "from keras.layers import Input, Embedding, SpatialDropout1D, Bidirectional, Dense\n",
    "from keras.layers import concatenate, CuDNNGRU, GlobalAveragePooling1D, GlobalMaxPooling1D\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import load_model\n",
    "from keras.models import Model\n",
    "\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "import tqdm\n",
    "import nltk\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "653aeac0650291ac33f969b5fdb0ca98ab7898b6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>question_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000163e3ea7c7a74cd7</td>\n",
       "      <td>Why do so many women become so rude and arroga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00002bd4fb5d505b9161</td>\n",
       "      <td>When should I apply for RV college of engineer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00007756b4a147d2b0b3</td>\n",
       "      <td>What is it really like to be a nurse practitio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000086e4b7e1c7146103</td>\n",
       "      <td>Who are entrepreneurs?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0000c4c3fbe8785a3090</td>\n",
       "      <td>Is education really making good people nowadays?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    qid                                      question_text\n",
       "0  0000163e3ea7c7a74cd7  Why do so many women become so rude and arroga...\n",
       "1  00002bd4fb5d505b9161  When should I apply for RV college of engineer...\n",
       "2  00007756b4a147d2b0b3  What is it really like to be a nurse practitio...\n",
       "3  000086e4b7e1c7146103                             Who are entrepreneurs?\n",
       "4  0000c4c3fbe8785a3090   Is education really making good people nowadays?"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv('../input/test.csv')\n",
    "test_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "7ff933f5c8ec9861b31b61c0c24527b1ff296ba8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>question_text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00002165364db923c7e6</td>\n",
       "      <td>How did Quebec nationalists see their province...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000032939017120e6e44</td>\n",
       "      <td>Do you have an adopted dog, how would you enco...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000412ca6e4628ce2cf</td>\n",
       "      <td>Why does velocity affect time? Does velocity a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000042bf85aa498cd78e</td>\n",
       "      <td>How did Otto von Guericke used the Magdeburg h...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0000455dfa3e01eae3af</td>\n",
       "      <td>Can I convert montra helicon D to a mountain b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    qid                                      question_text  \\\n",
       "0  00002165364db923c7e6  How did Quebec nationalists see their province...   \n",
       "1  000032939017120e6e44  Do you have an adopted dog, how would you enco...   \n",
       "2  0000412ca6e4628ce2cf  Why does velocity affect time? Does velocity a...   \n",
       "3  000042bf85aa498cd78e  How did Otto von Guericke used the Magdeburg h...   \n",
       "4  0000455dfa3e01eae3af  Can I convert montra helicon D to a mountain b...   \n",
       "\n",
       "   target  \n",
       "0       0  \n",
       "1       0  \n",
       "2       0  \n",
       "3       0  \n",
       "4       0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv('../input/train.csv')\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "a7afd7a540a1e0dbc0f90ffc97904eed8e0df014"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70.67883551459971, 38.78427671665139, 1017)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lens = train_df.question_text.str.len()\n",
    "lens.mean(), lens.std(), lens.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "611d346c1aed30f2d733767ca1e5ac3686dec349"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of questions:  1681928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:1: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "all_df = pd.concat([train_df ,test_df])\n",
    "\n",
    "print(\"Total number of questions: \", all_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "c5d5f56f704f4b7bb9c20573e15717aa63bc143e"
   },
   "outputs": [],
   "source": [
    "max_features = 100000\n",
    "ques_len= 72"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "9880452b510f3fb936669149c86400b5cea93f7d"
   },
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "UNKNOWN_WORD = \"_UNK_\"\n",
    "END_WORD = \"_END_\"\n",
    "NAN_WORD = \"_NAN_\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"question_text\"] = train_df[\"question_text\"].fillna(NAN_WORD)\n",
    "test_df[\"question_text\"] = test_df[\"question_text\"].fillna(NAN_WORD)\n",
    "sub = test_df[['qid']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "9dc175bc369d07b279c673a165bfbed24ac91760"
   },
   "outputs": [],
   "source": [
    "re_tok = re.compile(f'([{string.punctuation}“”¨«»®´·º½¾¿¡§£₤‘’])')\n",
    "\n",
    "def clean_text(s):\n",
    "    return re_tok.sub(r' \\1 ', s).lower()\n",
    "\n",
    "\n",
    "def clean_numbers(x):\n",
    "    x = re.sub('[0-9]{5,}', '#####', x)\n",
    "    x = re.sub('[0-9]{4}', '####', x)\n",
    "    x = re.sub('[0-9]{3}', '###', x)\n",
    "    x = re.sub('[0-9]{2}', '##', x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Cleaning train questions\n",
      "    Cleaning test questions\n",
      "    Removing numbers from train questions\n",
      "    Removing numbers from test questions\n",
      "CPU times: user 32.1 s, sys: 188 ms, total: 32.3 s\n",
      "Wall time: 32.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(\"    Cleaning train questions\")\n",
    "train_df[\"question_text\"] = train_df[\"question_text\"].apply(clean_text)\n",
    "print(\"    Cleaning test questions\")\n",
    "test_df[\"question_text\"] = test_df[\"question_text\"].apply(clean_text)\n",
    "\n",
    "print(\"    Removing numbers from train questions\")\n",
    "train_df[\"question_text\"] = train_df[\"question_text\"].apply(clean_numbers)\n",
    "print(\"    Removing numbers from test questions\")\n",
    "test_df[\"question_text\"] = test_df[\"question_text\"].apply(clean_numbers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenize text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 32.6 s, sys: 80 ms, total: 32.7 s\n",
      "Wall time: 32.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tokenizer = Tokenizer(num_words=max_features, oov_token=UNKNOWN_WORD)\n",
    "tokenizer.fit_on_texts(list(train_df[\"question_text\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 38.3 s, sys: 232 ms, total: 38.5 s\n",
      "Wall time: 38.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_X = tokenizer.texts_to_sequences(train_df[\"question_text\"])\n",
    "test_X = tokenizer.texts_to_sequences(test_df[\"question_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = pad_sequences(train_X, maxlen=ques_len)\n",
    "test_X = pad_sequences(test_X, maxlen=ques_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = train_df['target'].values\n",
    "# test_y = test_df['target'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "5cf5c43e43254053a4b66fb96334bf55c98ea924"
   },
   "source": [
    "## Loading Embedding file\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_uuid": "0796e9c3a9dde1d0f67a4733ed299bcb50ba6526"
   },
   "outputs": [],
   "source": [
    "embd_file =  '../input/embeddings/paragram_300_sl999/paragram_300_sl999.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_uuid": "9ee2de86ab439250183450280e89140245cb889b"
   },
   "outputs": [],
   "source": [
    "def load_embed(file):\n",
    "    def get_coefs(word,*arr): \n",
    "        return word, np.asarray(arr, dtype='float32')\n",
    "    \n",
    "    embeddings_index = dict(get_coefs(*o.split(\" \")) for o in open(file, encoding='latin'))\n",
    "        \n",
    "    return embeddings_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_uuid": "e6433ff0287a8dd3defe727f32e9f9606ac6bd07"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting Paragram embedding\n",
      "CPU times: user 2min 18s, sys: 5.24 s, total: 2min 23s\n",
      "Wall time: 2min 24s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(\"Extracting Paragram embedding\")\n",
    "embeddings_index = load_embed(embd_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Embedding matrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:1: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.65 s, sys: 1.98 s, total: 6.63 s\n",
      "Wall time: 6.66 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "all_embs = np.stack(embeddings_index.values())\n",
    "emb_mean,emb_std = all_embs.mean(), all_embs.std()\n",
    "embed_size = all_embs.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "## rebuilding embedding matrics\n",
    "nb_words = min(max_features, len(tokenizer.word_index))\n",
    "embedding_matrix = np.random.normal(emb_mean, emb_std, (nb_words, embed_size))\n",
    "\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    if i >= max_features:\n",
    "        continue\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None: \n",
    "        embedding_matrix[i] = embedding_vector\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 72)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 72, 300)      30000000    input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_1 (SpatialDro (None, 72, 300)      0           embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 72, 180)      211680      spatial_dropout1d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_2 (Bidirectional) (None, 72, 180)      146880      bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_1 (Glo (None, 180)          0           bidirectional_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_1 (GlobalM (None, 180)          0           bidirectional_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 360)          0           global_average_pooling1d_1[0][0] \n",
      "                                                                 global_max_pooling1d_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 256)          92416       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1)            257         dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 30,451,233\n",
      "Trainable params: 451,233\n",
      "Non-trainable params: 30,000,000\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_layer = Input(shape=(ques_len,))\n",
    "embedding_layer = Embedding(embedding_matrix.shape[0], embedding_matrix.shape[1],\n",
    "                            weights=[embedding_matrix], trainable=False)(input_layer)\n",
    "x = SpatialDropout1D(0.2)(embedding_layer)\n",
    "x = Bidirectional(CuDNNGRU(90, return_sequences=True))(x)\n",
    "x = Bidirectional(CuDNNGRU(90, return_sequences=True))(x)\n",
    "avg_pool = GlobalAveragePooling1D()(x)\n",
    "max_pool = GlobalMaxPooling1D()(x)\n",
    "x = concatenate([avg_pool, max_pool])\n",
    "x = Dense(256, activation=\"relu\")(x)\n",
    "output_layer = Dense(1, activation=\"sigmoid\")(x)\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "model.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer=Adam(lr=1e-3, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "checkpoint = ModelCheckpoint('saved-dmodel-{acc:03f}.h5', verbose=1, monitor='val_acc',save_best_only=True, mode='auto')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1175509 samples, validate on 130613 samples\n",
      "Epoch 1/8\n",
      "1175509/1175509 [==============================] - 319s 271us/step - loss: 0.1143 - acc: 0.9556 - val_loss: 0.1056 - val_acc: 0.9581\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.95806, saving model to saved-dmodel-0.955570.h5\n",
      "Epoch 2/8\n",
      " 202496/1175509 [====>.........................] - ETA: 4:11 - loss: 0.1020 - acc: 0.9598"
     ]
    }
   ],
   "source": [
    "model.fit(train_X, train_y, batch_size=128, validation_split=0.1, callbacks=[checkpoint], epochs=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375806/375806 [==============================] - 11s 30us/step\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict([test_X], batch_size=1024, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = preds.reshape((-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test_y = (preds>0.5).astype(int)\n",
    "sub['prediction'] = pred_test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv(\"submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
